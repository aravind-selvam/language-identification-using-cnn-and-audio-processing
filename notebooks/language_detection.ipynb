{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMd6oI5EJJAwqNqRvh8VEK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deep-Learning-01/language-detection-using-cnn-pytroch/blob/main/language_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyxGlGkC6Zdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971b11dd-01b8-46ce-a760-2f7fd364ce81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import warnings\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "13Tc0Q1eCahv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_zip_path = 'drive/MyDrive/004_Aravind/Language Identification/Dataset/raw_data/Subset of Language data.zip'\n",
        "target_dir = 'final_data'\n",
        "os.makedirs(target_dir)\n",
        "\n",
        "with zipfile.ZipFile(raw_zip_path,\"r\") as zip_f:\n",
        "    zip_f.extractall(target_dir)"
      ],
      "metadata": {
        "id": "z-eeMlssRnSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dir1 = os.path.join(target_dir,'Subset of Language data')\n",
        "os.listdir(audio_dir1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q26oWM6fvVsa",
        "outputId": "d30886a8-43fa-4146-da8c-f0113bf4fcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Kannada', 'Tamil', 'Telugu', 'Hindi']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = []\n",
        "for i in os.listdir(audio_dir1):\n",
        "    classes.append(i)\n",
        "    class_path = audio_dir1 + '/' + str(i)\n",
        "    audio_clips = os.listdir(class_path)\n",
        "    print(f\"No. of .mp3 files in audio {i} folder = \",len(audio_clips))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heuWSkze0eBO",
        "outputId": "7ba6c764-718f-4877-8009-a2b0e41cac4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of .mp3 files in audio Kannada folder =  3427\n",
            "No. of .mp3 files in audio Tamil folder =  5567\n",
            "No. of .mp3 files in audio Telugu folder =  7173\n",
            "No. of .mp3 files in audio Hindi folder =  7001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# os.makedirs(\"final_wav\", exist_ok=True)\n",
        "\n",
        "# for folder in os.listdir(audio_dir1):\n",
        "#     class_path = audio_dir1 + '/' + str(folder)\n",
        "#     for count, files in enumerate(os.listdir(class_path)):\n",
        "#       src = f\"{audio_dir1}/{folder}/{files}\"\n",
        "#       file_name = f\"{folder}-{str(count)}.wav\"\n",
        "#       dst = f\"final_wav/{folder}\"\n",
        "#       os.makedirs(dst, exist_ok=True)\n",
        "#       dst = f\"final_wav/{folder}/{file_name}\"\n",
        "#       sound = AudioSegment.from_mp3(src)\n",
        "#       sound.export(dst, format=\"wav\")"
      ],
      "metadata": {
        "id": "C-tS3zBaxBsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for folder in os.listdir(audio_dir1):\n",
        "#     class_path = audio_dir1 + '/' + str(folder)\n",
        "#     for count, files in enumerate(os.listdir(class_path)):\n",
        "#         try:\n",
        "#             dst = f\"{folder}-{str(count)}.mp3\"\n",
        "#             src =f\"{audio_dir1}/{folder}/{files}\"  \n",
        "#             dst =f\"{audio_dir1}/{folder}/{dst}\"\n",
        "#             os.rename(src, dst)\n",
        "#         except FileExistsError:\n",
        "#              pass"
      ],
      "metadata": {
        "id": "oJOM-4ERColZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "wav_dir = '/content/final_wav'\n",
        "# Create metadata dictionary\n",
        "metadata = {}\n",
        "for label in os.listdir(wav_dir):\n",
        "    class_path = wav_dir + '/' + str(label)\n",
        "    audio_clips = os.listdir(class_path)\n",
        "    for filename in audio_clips: \n",
        "        metadata[filename] = label\n",
        "\n",
        "# Create a metadata csv file\n",
        "metadata = pd.DataFrame.from_dict(metadata, orient='index').reset_index().sort_values(by=0)\n",
        "metadata.columns = ['filename', 'foldername']\n",
        "le = preprocessing.LabelEncoder()\n",
        "metadata['labels'] = le.fit_transform(metadata.foldername)\n",
        "metadata.to_csv('metadata.csv', index=False)\n",
        "metadata"
      ],
      "metadata": {
        "id": "YT3bJfeyC0cU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "56ac64f6-32a0-4774-de3c-f5e2692544e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              filename foldername  labels\n",
              "23167   Hindi-6947.wav      Hindi       0\n",
              "18493   Hindi-3028.wav      Hindi       0\n",
              "18494    Hindi-515.wav      Hindi       0\n",
              "18495   Hindi-3848.wav      Hindi       0\n",
              "18496   Hindi-6296.wav      Hindi       0\n",
              "...                ...        ...     ...\n",
              "13721  Telugu-2313.wav     Telugu       3\n",
              "13722  Telugu-3158.wav     Telugu       3\n",
              "13723  Telugu-4143.wav     Telugu       3\n",
              "13712    Telugu-84.wav     Telugu       3\n",
              "11583  Telugu-3112.wav     Telugu       3\n",
              "\n",
              "[23168 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20ee33bc-53a7-43de-8c71-ba1a3c3dd922\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>foldername</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23167</th>\n",
              "      <td>Hindi-6947.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18493</th>\n",
              "      <td>Hindi-3028.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18494</th>\n",
              "      <td>Hindi-515.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18495</th>\n",
              "      <td>Hindi-3848.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18496</th>\n",
              "      <td>Hindi-6296.wav</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13721</th>\n",
              "      <td>Telugu-2313.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13722</th>\n",
              "      <td>Telugu-3158.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13723</th>\n",
              "      <td>Telugu-4143.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13712</th>\n",
              "      <td>Telugu-84.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11583</th>\n",
              "      <td>Telugu-3112.wav</td>\n",
              "      <td>Telugu</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23168 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20ee33bc-53a7-43de-8c71-ba1a3c3dd922')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20ee33bc-53a7-43de-8c71-ba1a3c3dd922 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20ee33bc-53a7-43de-8c71-ba1a3c3dd922');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the mappings \n",
        "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(le_name_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6vQaOIzWqnU",
        "outputId": "012b0b14-4425-430e-d422-d74938a5816c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Hindi': 0, 'Kannada': 1, 'Tamil': 2, 'Telugu': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "4jQ8R9bnDXKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IndianLanguageDataset(Dataset):\n",
        "    def __init__(self, annotation_file, \n",
        "                 audio_dir, \n",
        "                 transformation, \n",
        "                 target_sample_rate,\n",
        "                 num_samples\n",
        "                 ):\n",
        "        self.annotations = pd.read_csv(annotation_file)\n",
        "        self.audio_dir = audio_dir\n",
        "        self.transformation = transformation\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.num_samples = num_samples\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        audio_sample_path = self._get_audio_sample_path(idx)\n",
        "        label = self._get_audio_sample_label(idx)\n",
        "        signal, sr = torchaudio.load(audio_sample_path)\n",
        "        signal = self._resample_if_necessary(signal, sr)\n",
        "        signal = self._mix_down_if_necessary(signal)\n",
        "        signal = self._cut_if_necessary(signal)\n",
        "        signal = self._right_pad_if_necessary(signal)\n",
        "        signal = self.transformation(signal)\n",
        "        return signal, label\n",
        "    \n",
        "    def _cut_if_necessary(self, signal):\n",
        "        if signal.shape[1] > self.num_samples:\n",
        "            signal = signal[:, :self.num_samples]\n",
        "        return signal\n",
        "    \n",
        "    def _right_pad_if_necessary(self, signal):\n",
        "        length_signal = signal.shape[1]\n",
        "        if length_signal < self.num_samples:\n",
        "            num_missing = self.num_samples - length_signal\n",
        "            last_dim_padding = (0, num_missing)\n",
        "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "        return signal\n",
        "        \n",
        "    def _resample_if_necessary(self, signal, sr):\n",
        "        if sr != self.target_sample_rate:\n",
        "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "            signal = resampler(signal)\n",
        "        return signal\n",
        "    \n",
        "    def _mix_down_if_necessary(self, signal):\n",
        "        if signal.shape[0] > 1:\n",
        "            signal = torch.mean(signal, dim = 0, keepdim=True)\n",
        "        return signal\n",
        "     \n",
        "    def _get_audio_sample_path(self, idx):\n",
        "        class_name = f\"{self.annotations.iloc[idx, 1]}\"\n",
        "        path = os.path.join(self.audio_dir, class_name, self.annotations.iloc[idx, 0])\n",
        "        return path\n",
        "    \n",
        "    def _get_audio_sample_label(self, idx):\n",
        "        return self.annotations.iloc[idx, 2]"
      ],
      "metadata": {
        "id": "I0xp-O5ZW0Zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformations"
      ],
      "metadata": {
        "id": "SZAzutv9Zr3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_RATE = 4000\n",
        "NUM_SAMPLES = 20000\n",
        "\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate = SAMPLE_RATE,\n",
        "    n_fft = 1024,\n",
        "    hop_length=512,\n",
        "    n_mels = 64\n",
        ")"
      ],
      "metadata": {
        "id": "7428iD0XZs7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ild = IndianLanguageDataset(annotation_file='metadata.csv', \n",
        "                            audio_dir=wav_dir, \n",
        "                            target_sample_rate=SAMPLE_RATE, \n",
        "                            transformation=mel_spectrogram,\n",
        "                            num_samples=NUM_SAMPLES\n",
        "                            )\n",
        "print(f\"there are {len(ild)} samples in the dataset\")\n",
        "signal, label = ild[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4O407Z-Zv6b",
        "outputId": "ac77db12-3ef8-482c-e85b-f89dd5aa90e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 23168 samples in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'signal:{signal.shape} \\n label: {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5kT3VkDCFxY",
        "outputId": "0ba52e99-2171-4b8a-945d-12bd989dd8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "signal:torch.Size([1, 64, 40]) \n",
            " label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Functions "
      ],
      "metadata": {
        "id": "qQvJDTlECmks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a pytorch Dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "K7WQ9xoFvnSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "8qvseNRqCqep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model Architecture"
      ],
      "metadata": {
        "id": "M4w8WnzxEWSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNetwork(ImageClassificationBase):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super().__init__()\n",
        "    self.conv1 = self.conv_block(in_channels, 16, pool=True) # 16 x 30 x 20\n",
        "    self.conv2 = self.conv_block(16, 32, pool=True) # 32 x 15 x 10\n",
        "    self.conv3 = self.conv_block(32, 64, pool=True) # 64 x 7 x 5\n",
        "    self.conv4 = self.conv_block(64, 128, pool=True) # 128 x 4 x 3\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.linear = nn.Linear(128 * 5 * 4, num_classes)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  @staticmethod\n",
        "  def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=2), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(kernel_size=2))\n",
        "    return nn.Sequential(*layers) \n",
        "\n",
        "  def forward(self, input_data):\n",
        "    out = self.conv1(input_data)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.flatten(out)\n",
        "    out = self.dropout(out)\n",
        "    logits = self.linear(out)\n",
        "    predictions = self.softmax(logits)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "EY8i-FzqEa0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNNNetwork(1, 4)\n",
        "summary(cnn.cuda(), (1,64, 40))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36J8ultVEasA",
        "outputId": "bf720360-e18c-4fbb-c394-de8b67a575bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 66, 42]             160\n",
            "       BatchNorm2d-2           [-1, 16, 66, 42]              32\n",
            "              ReLU-3           [-1, 16, 66, 42]               0\n",
            "         MaxPool2d-4           [-1, 16, 33, 21]               0\n",
            "            Conv2d-5           [-1, 32, 35, 23]           4,640\n",
            "       BatchNorm2d-6           [-1, 32, 35, 23]              64\n",
            "              ReLU-7           [-1, 32, 35, 23]               0\n",
            "         MaxPool2d-8           [-1, 32, 17, 11]               0\n",
            "            Conv2d-9           [-1, 64, 19, 13]          18,496\n",
            "      BatchNorm2d-10           [-1, 64, 19, 13]             128\n",
            "             ReLU-11           [-1, 64, 19, 13]               0\n",
            "        MaxPool2d-12             [-1, 64, 9, 6]               0\n",
            "           Conv2d-13           [-1, 128, 11, 8]          73,856\n",
            "      BatchNorm2d-14           [-1, 128, 11, 8]             256\n",
            "             ReLU-15           [-1, 128, 11, 8]               0\n",
            "        MaxPool2d-16            [-1, 128, 5, 4]               0\n",
            "          Flatten-17                 [-1, 2560]               0\n",
            "          Dropout-18                 [-1, 2560]               0\n",
            "           Linear-19                    [-1, 4]          10,244\n",
            "          Softmax-20                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 107,876\n",
            "Trainable params: 107,876\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.44\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 2.86\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hEci5PllX0kw",
        "outputId": "85eee0e9-6d85-48b7-d5f8-45dff55adb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A100-SXM4-40GB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "MjjGQGSkbnAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "-2azZHAvcaqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stratified shuffle split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=5,train_size= 0.7, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in split.split(metadata, metadata['labels']):\n",
        "    strat_train_set = metadata.loc[train_index]\n",
        "    strat_val_set = metadata.loc[test_index]\n",
        "\n",
        "strat_train_set.to_csv('metadata_train.csv', index=False)\n",
        "strat_val_set.to_csv('metadata_test.csv', index=False)"
      ],
      "metadata": {
        "id": "X5HnJGmBeD1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.001\n",
        "SAMPLE_RATE = 4000\n",
        "NUM_SAMPLES = 20000\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "\n",
        "# load adam optimizer\n",
        "optimiser = torch.optim.Adam\n",
        "\n",
        "# load mel_spectrogram transformation\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate = SAMPLE_RATE,\n",
        "    n_fft = 1024,\n",
        "    hop_length=512,\n",
        "    n_mels = 64\n",
        ")\n",
        "\n",
        "train_lang_data = IndianLanguageDataset(annotation_file='metadata_train.csv',\n",
        "                                        audio_dir = wav_dir,\n",
        "                                        target_sample_rate=SAMPLE_RATE, \n",
        "                                        transformation=mel_spectrogram,\n",
        "                                        num_samples=NUM_SAMPLES\n",
        "                                        )\n",
        "\n",
        "test_lang_data = IndianLanguageDataset(annotation_file='metadata_test.csv',\n",
        "                                       audio_dir= wav_dir,\n",
        "                                       target_sample_rate=SAMPLE_RATE,\n",
        "                                       transformation=mel_spectrogram,\n",
        "                                       num_samples=NUM_SAMPLES\n",
        "                                       )\n",
        "\n",
        "# dataloaders\n",
        "train_dl = DataLoader(train_lang_data, \n",
        "                      BATCH_SIZE, \n",
        "                      shuffle=True, \n",
        "                      num_workers=4, \n",
        "                      pin_memory=True\n",
        "                     )\n",
        "val_dl = DataLoader(test_lang_data\n",
        "                    ,BATCH_SIZE*2,\n",
        "                    num_workers=4,\n",
        "                    pin_memory=True\n",
        "                    )"
      ],
      "metadata": {
        "id": "X1xoFgZ_cWkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get default device\n",
        "device = get_default_device()\n",
        "\n",
        "# move model to device\n",
        "model = to_device(CNNNetwork(1, 4), device)\n",
        "\n",
        "# Use the wrapper class to load data to the device\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)"
      ],
      "metadata": {
        "id": "QwspMubkarJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get validation accuracy for default random weights and bias(model)\n",
        "evaluate(model, val_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVHPd0mdeIpZ",
        "outputId": "113badd3-db89-433e-b3fc-076645cf0fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 1.6236017942428589, 'val_acc': 0.13972902297973633}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the model for 30 epochs"
      ],
      "metadata": {
        "id": "NV4dlbfkg5mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(EPOCHS, LEARNING_RATE, model, train_dl, val_dl, optimiser)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOI40Gwbgpsb",
        "outputId": "45fe5d4a-30d3-41b9-99ad-caac00f7b5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], train_loss: 0.9492, val_loss: 0.8450, val_acc: 0.9009\n",
            "Epoch [1], train_loss: 0.8342, val_loss: 0.8517, val_acc: 0.8901\n",
            "Epoch [2], train_loss: 0.8158, val_loss: 0.8285, val_acc: 0.9158\n",
            "Epoch [3], train_loss: 0.8067, val_loss: 0.8186, val_acc: 0.9233\n",
            "Epoch [4], train_loss: 0.8060, val_loss: 0.8136, val_acc: 0.9304\n",
            "Epoch [5], train_loss: 0.8005, val_loss: 0.7982, val_acc: 0.9460\n",
            "Epoch [6], train_loss: 0.7972, val_loss: 0.8085, val_acc: 0.9341\n",
            "Epoch [7], train_loss: 0.7966, val_loss: 0.8035, val_acc: 0.9388\n",
            "Epoch [8], train_loss: 0.7974, val_loss: 0.9030, val_acc: 0.8351\n",
            "Epoch [9], train_loss: 0.7930, val_loss: 0.8002, val_acc: 0.9440\n",
            "Epoch [10], train_loss: 0.7902, val_loss: 0.8418, val_acc: 0.9004\n",
            "Epoch [11], train_loss: 0.7888, val_loss: 0.7950, val_acc: 0.9486\n",
            "Epoch [12], train_loss: 0.7884, val_loss: 0.7936, val_acc: 0.9502\n",
            "Epoch [13], train_loss: 0.7869, val_loss: 0.8026, val_acc: 0.9375\n",
            "Epoch [14], train_loss: 0.7869, val_loss: 0.7964, val_acc: 0.9475\n",
            "Epoch [15], train_loss: 0.7849, val_loss: 0.7857, val_acc: 0.9577\n",
            "Epoch [16], train_loss: 0.7860, val_loss: 0.7930, val_acc: 0.9500\n",
            "Epoch [17], train_loss: 0.7884, val_loss: 0.7932, val_acc: 0.9496\n",
            "Epoch [18], train_loss: 0.7838, val_loss: 0.7894, val_acc: 0.9546\n",
            "Epoch [19], train_loss: 0.7845, val_loss: 0.7923, val_acc: 0.9509\n",
            "Epoch [20], train_loss: 0.7842, val_loss: 0.7882, val_acc: 0.9551\n",
            "Epoch [21], train_loss: 0.7831, val_loss: 0.7893, val_acc: 0.9548\n",
            "Epoch [22], train_loss: 0.7837, val_loss: 0.8078, val_acc: 0.9362\n",
            "Epoch [23], train_loss: 0.7837, val_loss: 0.7887, val_acc: 0.9547\n",
            "Epoch [24], train_loss: 0.7818, val_loss: 0.7900, val_acc: 0.9522\n",
            "Epoch [25], train_loss: 0.7816, val_loss: 0.7862, val_acc: 0.9580\n",
            "Epoch [26], train_loss: 0.7801, val_loss: 0.8132, val_acc: 0.9310\n",
            "Epoch [27], train_loss: 0.7763, val_loss: 0.7824, val_acc: 0.9615\n",
            "Epoch [28], train_loss: 0.7748, val_loss: 0.7860, val_acc: 0.9579\n",
            "Epoch [29], train_loss: 0.7747, val_loss: 0.7911, val_acc: 0.9520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Trained feed forward net saved at model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg0cPvWgrx5Z",
        "outputId": "0cb7d948-e605-40da-9a01-edf672398265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained feed forward net saved at model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "jeX4ezQlpJAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = ['Hindi',\n",
        "                 'Kannada',\n",
        "                 'Tamil',\n",
        "                 'Telugu']\n",
        "\n",
        "\n",
        "def predict(model, input, target, class_mapping):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input)\n",
        "        predicted_index = predictions[0].argmax(0)\n",
        "        predicted = class_mapping[predicted_index]\n",
        "        expected = class_mapping[target]\n",
        "    return predicted, expected"
      ],
      "metadata": {
        "id": "sYeDlNtzovlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load back the model\n",
        "state_dict = torch.load(\"model.pth\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# get a sample from the urban sound dataset for inference\n",
        "\n",
        "torch.device('cpu')\n",
        "model.to(device='cpu')\n",
        "testinput, target = test_lang_data[1][0], test_lang_data[1][1] # [batch size, num_channels, fr, time]\n",
        "testinput.unsqueeze_(0)\n",
        "\n",
        "\n",
        "# make an inference\n",
        "predicted, expected = predict(model, testinput, target, class_mapping)\n",
        "print(f\"Predicted: '{predicted}', expected: '{expected}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLPAVhSzppmJ",
        "outputId": "25c9b419-486f-40dd-dd6b-33cde182a97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 'Tamil', expected: 'Tamil'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot accuracy"
      ],
      "metadata": {
        "id": "xA5BTLO5hPvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');"
      ],
      "metadata": {
        "id": "xDi8d0eZhIBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Sl9JELv9hVMJ",
        "outputId": "a064024b-16db-48ec-b6cb-6ba1e65f5e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "own_voice = {}\n",
        "own_voice['filename'] = ['own_1.wav']\n",
        "own_voice['foldername'] = ['Tamil']\n",
        "own_voice['labels'] = [2]\n",
        "pd.DataFrame.from_dict(own_voice).to_csv('own.csv', index=False)"
      ],
      "metadata": {
        "id": "CGtjzHdNhV27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "own_voice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLZQdbXv0gEx",
        "outputId": "3dfbda9e-42e5-48ce-e0fd-8301b2bacb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'filename': ['own_1.wav'], 'foldername': ['Tamil'], 'labels': [2]}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_1 = test_lang_data = IndianLanguageDataset(annotation_file='own.csv',\n",
        "                                       audio_dir= '/content/own',\n",
        "                                       target_sample_rate=SAMPLE_RATE,\n",
        "                                       transformation=mel_spectrogram,\n",
        "                                       num_samples=NUM_SAMPLES\n",
        "                                       )"
      ],
      "metadata": {
        "id": "1lwr3iQOzZJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testinput, target = test_lang_data[0][0], test_lang_data[0][1]\n",
        "testinput.unsqueeze_(0)\n",
        "\n",
        "predicted, expected = predict(model, testinput, target, class_mapping)\n",
        "print(f\"Predicted: '{predicted}', expected: '{expected}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w3JG_U515Tn",
        "outputId": "f98ea55d-84e0-4ff2-ce64-13fe8e87cdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 'Telugu', expected: 'Tamil'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(testinput)\n",
        "    predicted_index = predictions[0].argmax(0)\n",
        "    predicted = class_mapping[predicted_index]\n",
        "    expected = class_mapping[target]"
      ],
      "metadata": {
        "id": "YatnaWXv2F1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0MzsDZk2a-r",
        "outputId": "8f38810e-fd37-45a2-bbf4-959423d788d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "99d_t9yJ2cNs",
        "outputId": "1e1b3056-8c9d-48d4-e9a1-863853f9695b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tamil'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7c52zN6A2dkz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
